{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-be04296579c3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-be04296579c3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ```\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Cleanly written notebook of python commands for producing blog figures\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marvel_Data/Marvel-Superheroes/characters.csv',\n",
       " 'Marvel_Data/Marvel-Superheroes/characters_stats.csv',\n",
       " 'Marvel_Data/Marvel-Superheroes/charactersToComics.csv',\n",
       " 'Marvel_Data/Marvel-Superheroes/comics.csv',\n",
       " 'Marvel_Data/Marvel-Superheroes/hero-network.csv',\n",
       " 'Marvel_Data/Marvel-Superheroes/marvel_characters_info.csv',\n",
       " 'Marvel_Data/Marvel-Superheroes/marvel_dc_characters.csv',\n",
       " 'Marvel_Data/Marvel-Superheroes/superheroes_power_matrix.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import ALL data\n",
    "## We will merge 'character_stats' and 'superheroes_power_matrix'\n",
    "\n",
    "csv_files = !ls -1 'Marvel_Data'/Marvel-Superheroes/*.csv\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-73d2733b5c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Marvel_Data/Marvel-Superheroes/marvel_dc_characters.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Example csv\n",
    "pd.read_csv('Marvel_Data/Marvel-Superheroes/marvel_dc_characters.csv',encoding = \"ISO-8859-1\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all dataframes into a datafram dictionary: df_dict2\n",
    "## 'First appearance' feature above in marvel_dc_characters needs special encoding, see above\n",
    "\n",
    "df_dict2 = {}\n",
    "for csv_f in csv_files: \n",
    "  k = csv_f.split('/')[-1]\n",
    "  k = k.split('.')[0] #to get name with the csv extenstion\n",
    "  #print(k)\n",
    "  if[k==\"marvel_dc_characters\"]:\n",
    "        df_dict2[k] = pd.read_csv(csv_f,encoding = \"ISO-8859-1\")\n",
    "  else:\n",
    "    df_dict2[k] = pd.read_csv(csv_f)\n",
    "df_dict2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes\n",
    "\n",
    "print(df_dict2['characters'].shape, df_dict2['charactersToComics'].shape, df_dict2['characters_stats'].shape,\"\\n\")\n",
    "\n",
    "print(df_dict2['comics'].shape, df_dict2['hero-network'].shape, df_dict2['marvel_characters_info'].shape,\"\\n\")\n",
    "\n",
    "print(df_dict2['marvel_dc_characters'].shape, df_dict2['superheroes_power_matrix'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superpower list for each character. 168 total powers, we will not use so many for our model...\n",
    "df_dict2['superheroes_power_matrix'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# character_stats sample data\n",
    "## notice: not all stats are included, we will count how many like this later...\n",
    "df_dict2['characters_stats'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch out for FRANKLIN STORM, the only superhero with Power=0 and ACTUAL STATS\n",
    "df_dict2['characters_stats'][(df_dict2['characters_stats']['Power']==0) & \n",
    "                             (df_dict2['characters_stats']['Intelligence']>1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "super_data = df_dict2['characters_stats']\n",
    "super_data = super_data.merge(df_dict2['superheroes_power_matrix'], on='Name')\n",
    "super_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our total observations = 519   \n",
    "super_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 104 observations with NO STATS will need to impute\n",
    "super_data[super_data['Power'] ==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've now cut 39,648 total superhero characters in Marvel/DC-Comics Universe to only\n",
    "#   519 characters with stats AND superpowers  :( \n",
    "\n",
    "# This list is mostly among the MOST popular characters in the superhero universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we get started, let's see the publication years of our TOTAL comicbook dataset\n",
    "# We see our comics span 1939-2019. An 80 year span!\n",
    "\n",
    "#-----Unused-----------\n",
    "## Creating a filter to find the comics with least 8 characters in \n",
    "comicsWith7orMoreCharacterFilter=df_dict2['charactersToComics'].groupby(by='comicID').count()['characterID']>7\n",
    "## Applying the filter and find comics with 7+ characters in it\n",
    "comicsWith7orMoreCharacterData=df_dict2['charactersToComics'].groupby(by='comicID').count()[comicsWith7orMoreCharacterFilter]\n",
    "#-----Unused-----------\n",
    "\n",
    "#Finding year of the comics\n",
    "## First, creating a function to extract the year from comics title column\n",
    "def extractYear(txt):\n",
    "    startChr=txt.find('(')+1\n",
    "    endChr=txt.find(')')\n",
    "    try:\n",
    "        result=int(txt[startChr:endChr])\n",
    "        return result\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# Creating a copy of comics data frame\n",
    "comicsWyear=df_dict2['comics'].copy()\n",
    "\n",
    "# Applying extractYear function and creating a new column that contains year of the comics\n",
    "comicsWyear['year']=df_dict2['comics']['title'].apply(extractYear)\n",
    "\n",
    "# Creating a bar chart\n",
    "comicsWyear.groupby(by='year').count()['comicID'].plot(kind='bar',figsize=(18,12));\n",
    "plt.title('Comics Printed per Year')\n",
    "\n",
    "del comicsWyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in progress... need to show popularity of our tiny subsample as valid representation \n",
    "# of 'good' vs 'bad' divide.\n",
    "\n",
    "# Improve model:  add popularity feature (comic book appearances)\n",
    "#                 add 'year-character-created'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we move on...\n",
    "## Three alginment types will be reduced to two \n",
    "## for more accurate labeling of data and to go easier on our model\n",
    "\n",
    "# BEFORE\n",
    "super_data['Alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AFTER\n",
    "super_data['Alignment'] = super_data['Alignment'].apply(lambda x: 'bad' if x==\"neutral\" or x==\"bad\"  \n",
    "                                                          else 'good')\n",
    "super_data['Alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a feel for our stats data...\n",
    "## Let's first isolate for only data with data ... cutting ~20% data that we will return shortly\n",
    "super_data_w_stats = super_data[super_data['Power'] != 0]\n",
    "super_data_w_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total power stat of our subsample of Heroes w Stats shows:\n",
    "## 'bad' superheroes have higher stats\n",
    "\n",
    "import seaborn as sns\n",
    "#print(df_dict2['characters_stats'].groupby(by='Alignment').agg(['count','mean','sum'])['Total'])\n",
    "print('Total power of \\'bad\\' guys are greater than \\'good\\' guys')\n",
    "print(super_data_w_stats.groupby(by='Alignment').agg(['count','mean','sum'])['Total'])\n",
    "\n",
    "sns.boxplot(x='Alignment',\n",
    "           y='Total',\n",
    "         #  data=df_dict2['characters_stats']);\n",
    "           data=super_data_w_stats);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the boxplot another way...\n",
    "\n",
    "# Our stat distributions look mostly gaussian. \n",
    "# 'bad' types are slightly left-skewed: No weak bad guys, superstrong are restricted to bad\n",
    "\n",
    "#Filter Good and Bad Guys\n",
    "filterGood=super_data_w_stats['Alignment'].isin(['good'])\n",
    "filterBad =super_data_w_stats['Alignment'].isin(['bad'])\n",
    "\n",
    "#Creating a figure for 2 plots\n",
    "f,(ax1,ax2)=plt.subplots(2,1,figsize=(7,7), sharex=True, sharey=True);\n",
    "\n",
    "#Plot the data and show the distribution\n",
    "sns.distplot(super_data_w_stats[filterGood]['Total'],ax=ax1);\n",
    "ax1.set_ylabel(\"Good\");\n",
    "sns.distplot(super_data_w_stats[filterBad]['Total'],ax=ax2);\n",
    "ax2.set_ylabel(\"Bad\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual stats show 'good' vs 'bad' discrepancy mostly exists in Intelligence, Strength, and Durability\n",
    "\n",
    "stat_cols = ['Intelligence_x', 'Strength', 'Speed', 'Durability_x', 'Combat', 'Power']\n",
    "\n",
    "super_data_w_stats [ super_data_w_stats['Alignment'] == 'bad'][stat_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data_w_stats [ super_data_w_stats['Alignment'] == 'good'][stat_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample scatter plot to see rough feel for correlation of stats\n",
    "super_data_w_stats.plot(kind='scatter', x='Strength',y='Intelligence_x',alpha=0.5,color='blue')\n",
    "super_data_w_stats.xlabel1=('Strength')\n",
    "super_data_w_stats.ylabel1=('Intelligence')\n",
    "plt.title('Intelligence vs Strength');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's switch to getting a feel of our superpowers\n",
    "## See our 168 types of superpowers\n",
    "\n",
    "superhero_powers = df_dict2['superheroes_power_matrix']\n",
    "superpower_columns = list(superhero_powers.columns)\n",
    "superpower_columns.remove('Name')\n",
    "\n",
    "superpower_list = list(superhero_powers.columns)\n",
    "superpower_list.sort()\n",
    "superpower_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll want to cut some of our superpower features to limit our model for now\n",
    "## We'll show the powers with less than 20 characters than hold them\n",
    "## Preferable to keep and manage smartly for model\n",
    "\n",
    "columns_to_remove=[]\n",
    "for column in superpower_columns:\n",
    "    if (int(superhero_powers[column].sum()) < 30):\n",
    "        print(column, superhero_powers[column].sum())\n",
    "        columns_to_remove.append(column)\n",
    "        \n",
    "print(\"\\nWe will cut\", len(columns_to_remove), \"superpower features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in progress ... try to show superpowers correlated to other superpowers \n",
    "#                                 AND superpowers correlated to good vs bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's remind our superhero data\n",
    "super_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle our data to impute stats for no-stat-characters and cut some superpowers\n",
    "\n",
    "\n",
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # IMPUTATION\n",
    "    stat_cols = ['Intelligence_x', 'Strength', 'Speed', 'Durability_x', 'Combat', 'Power']\n",
    "    for col in stat_cols:\n",
    "        impute_val = X[X['Power']!=0][col].mean()\n",
    "\n",
    "        def impute_stat(row):\n",
    "            if row['Power']==0:\n",
    "                return impute_val\n",
    "            else:\n",
    "                return row[col]\n",
    "\n",
    "        X[col] = X.apply(impute_stat, axis=1)\n",
    "\n",
    "        if col==stat_cols[0]: \n",
    "            X['Total']=0\n",
    "        X['Total'] = X['Total'] + X[col]\n",
    "        \n",
    "    # CUT SUPERPOWERS\n",
    "    ## Remove superpower columns with num superheroes listed below cutoff  \n",
    "    ## Should probably fix double-features 'Durability' and 'Intelligence' stats vs powers\n",
    "    cutoff = 30\n",
    "    superpower_columns = list(df_dict2['superheroes_power_matrix'].columns)\n",
    "    superpower_columns.remove('Name')\n",
    "    \n",
    "    columns_to_remove=[]\n",
    "    for col in superpower_columns:\n",
    "       if (int(df_dict2['superheroes_power_matrix'][col].sum()) < cutoff):\n",
    "           #print(col, superhero_powers[col].sum())\n",
    "           columns_to_remove.append(col)\n",
    "   \n",
    "    X = X.drop(list(columns_to_remove),1)  \n",
    "    \n",
    "    return X\n",
    "\n",
    "super_data_wrangled = wrangle(super_data)\n",
    "super_data_wrangled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data_wrangled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data_wrangled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data_wrangled['Alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TARGET = 'Alignment'\n",
    "\n",
    "target = 'Alignment'\n",
    "train = super_data_wrangled\n",
    "\n",
    "X_train = train.drop(columns=target)\n",
    "X_train = X_train.drop('Name',axis=1)\n",
    "y_train = super_data_wrangled[target]\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE ACCURACY\n",
    "\n",
    "majority_class = y_train.mode()[0]\n",
    "y_pred = [majority_class]*len(y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study model quality with train and val data. ( 80% train | 20% val )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                  stratify=train[target], random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check alignment proportion pt1\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check alignment proportion pt2\n",
    "y_val.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initally, RANDOM FOREST MODEL\n",
    "\n",
    "# By the way, if only 'stats'      columns are used, accuracy score = .70\n",
    "#             if only 'superpower' columns are used, accuracy score = .64\n",
    "# Therefore, inclusion of both features crucial for beating baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "accuracy_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "importances = pd.Series(model.feature_importances_, X_train.columns)\n",
    "importances.sort_values().plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, Improved model: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "eval_set = [\n",
    "    (X_train, y_train),\n",
    "    (X_val, y_val)\n",
    "]\n",
    "\n",
    "#model = XGBClassifier(n_estimators=2000, n_jobs=-1)\n",
    "\n",
    "model = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx', \n",
    "                      num_class = 3, maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                      max_depth = 20, colsample_bytree = .4, n_jobs = -1, random_state=42,\n",
    "                     )\n",
    "\n",
    "model.fit(X_train,y_train, \n",
    "         eval_set=eval_set,\n",
    "         early_stopping_rounds=20\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST SCORE\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance drastically changes upon hypertuning optimization is welcomed\n",
    "\n",
    "importances = pd.Series(model.feature_importances_, X_train.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "n = len(X_train.columns)\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of some strong predictors. Normally, good:bad ratio is about 2.4 : 1\n",
    "## Strong predictor 1 - good:bad ratio almost 1 highly doesn't match blind ratio... \n",
    "train[train['Molecular Manipulation']==True]['Alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Strong predictor 2 - high frequency superpower & \n",
    "##                      ratio of ~1.75 doesn't match blind good:ratio \n",
    "train[train['Super Strength']==True]['Alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-762901c5672a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Weak predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cold Resistance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Alignment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# Weak predictor \n",
    "train[train['Cold Resistance']==True]['Alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERMUTATION IMPORTANCE\n",
    "## (note: high errors)\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "permuter = PermutationImportance(model, scoring='accuracy', \n",
    "                                 cv='prefit', n_iter=5, random_state=42)\n",
    "\n",
    "permuter.fit(X_val, y_val)\n",
    "feature_names = X_val.columns.tolist()\n",
    "eli5.show_weights(permuter, top=None, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Dependece Plots (PDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDP Intelligence\n",
    "## Moderate intelligence suggests \"good\" alignment but high intelligence suggest \"bad\"\n",
    "\n",
    "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "\n",
    "feature = 'Intelligence_x'\n",
    "\n",
    "isolated = pdp_isolate(\n",
    "    model=model, \n",
    "    dataset=X_val, \n",
    "    model_features=X_val.columns, \n",
    "    feature=feature\n",
    ")\n",
    "\n",
    "pdp_plot(isolated, feature_name=feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDP Total stat\n",
    "## Total stat indicates super-duper statatiscally strong characters typically 'bad'\n",
    "\n",
    "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "\n",
    "feature = 'Total'\n",
    "\n",
    "isolated = pdp_isolate(\n",
    "    model=model, \n",
    "    dataset=X_val, \n",
    "    model_features=X_val.columns, \n",
    "    feature=feature\n",
    ")\n",
    "\n",
    "pdp_plot(isolated, feature_name=feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDP Super Strength power\n",
    "## Superpower PDP's all show a small, high variance effect for prediction\n",
    "\n",
    "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "\n",
    "feature = 'Super Strength'\n",
    "\n",
    "isolated = pdp_isolate(\n",
    "    model=model, \n",
    "    dataset=X_val, \n",
    "    model_features=X_val.columns, \n",
    "    feature=feature\n",
    ")\n",
    "\n",
    "pdp_plot(isolated, feature_name=feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDP Super Strength power\n",
    "## Superpower PDP's all show high variance in effect\n",
    "\n",
    "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "\n",
    "feature = 'Time Travel'\n",
    "\n",
    "isolated = pdp_isolate(\n",
    "    model=model, \n",
    "    dataset=X_val, \n",
    "    model_features=X_val.columns, \n",
    "    feature=feature\n",
    ")\n",
    "\n",
    "pdp_plot(isolated, feature_name=feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------DONE-----------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation ought to be performed for our small/median dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly-dash is work in progess... When user inputs stats/superpowers, \n",
    "# tell user their character is most like _______ (ex. Thanos i.e. similarity score _____ -> bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict this data to MARVEL data NOT DC-Comics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nemesis Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAPLEY PLOTS (still in development)\n",
    "## Pick out some characters to briefly look at: Thanos, Spider-Man\n",
    "## Preliminary test results show reverse of model expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict2['characters_stats'][df_dict2['characters_stats']['Name']=='Thanos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_prediction = X_train[101:102]\n",
    "data_for_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train[101:102])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "shap_values = explainer.shap_values(data_for_prediction)\n",
    "shap_values\n",
    "\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict2['characters_stats'][df_dict2['characters_stats']['Name']=='Spider-Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_prediction = X_train[171:172]\n",
    "data_for_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "shap_values = explainer.shap_values(data_for_prediction)\n",
    "shap_values\n",
    "\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
